{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "921b993f-d599-4fe8-b125-37891ee82070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n* 'schema_extra' has been renamed to 'json_schema_extra'\n  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Azure Environment Configuration:\n   resource_group: irish-healthcare-agents-west-europe\n   databricks_workspace: irish-healthcare-db\n   storage_account: irishhealthdata\n   location: westeurope\n   container_name: supply-chain-data\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Container already exists: supply-chain-data\n✅ Azure Storage connection established successfully!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database 'supply_chain_analysis' created\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bronze layer tables created\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ports dimension table created with 17 major global ports\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>port_name</th><th>latitude</th><th>longitude</th><th>country</th><th>port_size</th><th>capacity_rating</th><th>region</th></tr></thead><tbody><tr><td>Shanghai</td><td>31.2304</td><td>121.4737</td><td>China</td><td>Major</td><td>Very High</td><td>Asia</td></tr><tr><td>Singapore</td><td>1.2644</td><td>103.822</td><td>Singapore</td><td>Major</td><td>Very High</td><td>Asia</td></tr><tr><td>Shenzhen</td><td>22.5431</td><td>114.0579</td><td>China</td><td>Major</td><td>High</td><td>Asia</td></tr><tr><td>Ningbo-Zhoushan</td><td>29.8686</td><td>121.5433</td><td>China</td><td>Major</td><td>High</td><td>Asia</td></tr><tr><td>Hong Kong</td><td>22.3193</td><td>114.1694</td><td>China</td><td>Major</td><td>High</td><td>Asia</td></tr><tr><td>Busan</td><td>35.1796</td><td>129.0756</td><td>South Korea</td><td>Major</td><td>High</td><td>Asia</td></tr><tr><td>Qingdao</td><td>36.0671</td><td>120.3826</td><td>China</td><td>Major</td><td>Medium</td><td>Asia</td></tr><tr><td>Rotterdam</td><td>51.9225</td><td>4.47917</td><td>Netherlands</td><td>Major</td><td>High</td><td>Europe</td></tr><tr><td>Antwerp</td><td>51.2291</td><td>4.4053</td><td>Belgium</td><td>Major</td><td>High</td><td>Europe</td></tr><tr><td>Hamburg</td><td>53.5511</td><td>9.9937</td><td>Germany</td><td>Major</td><td>High</td><td>Europe</td></tr><tr><td>Felixstowe</td><td>51.9617</td><td>1.3513</td><td>UK</td><td>Major</td><td>Medium</td><td>Europe</td></tr><tr><td>Valencia</td><td>39.4699</td><td>-0.3763</td><td>Spain</td><td>Major</td><td>Medium</td><td>Europe</td></tr><tr><td>Los Angeles</td><td>33.7175</td><td>-118.2675</td><td>USA</td><td>Major</td><td>High</td><td>North America</td></tr><tr><td>Long Beach</td><td>33.7623</td><td>-118.1954</td><td>USA</td><td>Major</td><td>High</td><td>North America</td></tr><tr><td>New York</td><td>40.6895</td><td>-74.1745</td><td>USA</td><td>Major</td><td>High</td><td>North America</td></tr><tr><td>Savannah</td><td>32.0814</td><td>-81.0914</td><td>USA</td><td>Major</td><td>Medium</td><td>North America</td></tr><tr><td>Vancouver</td><td>49.2827</td><td>-123.1207</td><td>Canada</td><td>Major</td><td>Medium</td><td>North America</td></tr><tr><td>Jebel Ali</td><td>25.0263</td><td>55.0564</td><td>UAE</td><td>Major</td><td>High</td><td>Middle East</td></tr><tr><td>Salalah</td><td>16.9344</td><td>54.0239</td><td>Oman</td><td>Major</td><td>Medium</td><td>Middle East</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Shanghai",
         31.2304,
         121.4737,
         "China",
         "Major",
         "Very High",
         "Asia"
        ],
        [
         "Singapore",
         1.2644,
         103.822,
         "Singapore",
         "Major",
         "Very High",
         "Asia"
        ],
        [
         "Shenzhen",
         22.5431,
         114.0579,
         "China",
         "Major",
         "High",
         "Asia"
        ],
        [
         "Ningbo-Zhoushan",
         29.8686,
         121.5433,
         "China",
         "Major",
         "High",
         "Asia"
        ],
        [
         "Hong Kong",
         22.3193,
         114.1694,
         "China",
         "Major",
         "High",
         "Asia"
        ],
        [
         "Busan",
         35.1796,
         129.0756,
         "South Korea",
         "Major",
         "High",
         "Asia"
        ],
        [
         "Qingdao",
         36.0671,
         120.3826,
         "China",
         "Major",
         "Medium",
         "Asia"
        ],
        [
         "Rotterdam",
         51.9225,
         4.47917,
         "Netherlands",
         "Major",
         "High",
         "Europe"
        ],
        [
         "Antwerp",
         51.2291,
         4.4053,
         "Belgium",
         "Major",
         "High",
         "Europe"
        ],
        [
         "Hamburg",
         53.5511,
         9.9937,
         "Germany",
         "Major",
         "High",
         "Europe"
        ],
        [
         "Felixstowe",
         51.9617,
         1.3513,
         "UK",
         "Major",
         "Medium",
         "Europe"
        ],
        [
         "Valencia",
         39.4699,
         -0.3763,
         "Spain",
         "Major",
         "Medium",
         "Europe"
        ],
        [
         "Los Angeles",
         33.7175,
         -118.2675,
         "USA",
         "Major",
         "High",
         "North America"
        ],
        [
         "Long Beach",
         33.7623,
         -118.1954,
         "USA",
         "Major",
         "High",
         "North America"
        ],
        [
         "New York",
         40.6895,
         -74.1745,
         "USA",
         "Major",
         "High",
         "North America"
        ],
        [
         "Savannah",
         32.0814,
         -81.0914,
         "USA",
         "Major",
         "Medium",
         "North America"
        ],
        [
         "Vancouver",
         49.2827,
         -123.1207,
         "Canada",
         "Major",
         "Medium",
         "North America"
        ],
        [
         "Jebel Ali",
         25.0263,
         55.0564,
         "UAE",
         "Major",
         "High",
         "Middle East"
        ],
        [
         "Salalah",
         16.9344,
         54.0239,
         "Oman",
         "Major",
         "Medium",
         "Middle East"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "port_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "port_size",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "capacity_rating",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "region",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MLflow experiment configured: /Users/u1025325052@gmail.com/supply_chain_risk_prediction\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D Running Environment Validation...\n✅ Test 1: Database accessible\n✅ Test 2: 3 tables exist\n✅ Test 3: MLflow experiment configured\n✅ Test 4: Azure Storage connected\n✅ Test 5: Spark operations working\n\n\uD83C\uDFAF Validation Results: 5/5 tests passed\n\uD83D\uDE80 Environment is READY for data ingestion!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCBE Saving configuration with ACTUAL values:\n   • GNews API Key in config: ✅ PRESENT\n   • GNews API Key value: cd8e55ad6d...\n   • GDACS URL: https://www.gdacs.org/gdacsapi/api/events/geteventlist/SEARCH\n✅ Configuration saved to: /dbfs/FileStore/supply_chain/config.json\n\n\uD83D\uDD0D VERIFYING SAVED CONFIGURATION:\n   • GNews API Key saved: cd8e55ad6d...\n   • GDACS URL saved: https://www.gdacs.org/gdacsapi/api/events/geteventlist/SEARCH\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n    \uD83C\uDF89 ENVIRONMENT SETUP COMPLETE!\n    \n    Next steps:\n    1. ✅ Replace GNews API key in the configuration\n    2. ➡️ Proceed to Notebook 2: Data Ingestion Pipeline\n    3. \uD83D\uDD27 Configure Azure OpenAI (optional for now)\n    \n    Your Azure Resources:\n    • Resource Group: irish-healthcare-agents-west-europe\n    • Databricks: irish-healthcare-db\n    • Storage: irishhealthdata\n    • Location: West Europe\n    \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 CURRENT CONFIGURATION STATUS:\n   Storage Account: irishhealthdata ✅\n   Database: supply_chain_analysis ✅\n   MLflow Experiment: /Users/u1025325052@gmail.com/supply_chain_risk_prediction ✅\n   GNews API Key: ✅ CONFIGURED\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment imported from Notebook 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 USING DIRECT API CONFIGURATION:\n   • GNews API: ✅ CONFIGURED\n   • GDACS API: ✅ READY\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bronze tables created with explicit schemas\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDE80 STARTING REAL DATA INGESTION PIPELINE...\n============================================================\n\uD83D\uDCDD NOTE: Using REAL APIs only - No sample data generation\n\uD83D\uDD2C MLflow Run Started: ae1c7cc901534b9a8cf4e94e78920985\n\n1. Ingesting GDACS Disaster Data...\n\uD83C\uDF2A️ Fetching REAL disaster data from GDACS API...\n   • API Endpoint: https://www.gdacs.org/gdacsapi/api/events/geteventlist/SEARCH\n   • Search Period: Last 30 days\n   • Alert Levels: All\n   • Response Status: 200\n   • Found 100 features in API response\n✅ Successfully collected 100 REAL disaster events\n   • Event Types: ['TC', 'EQ', 'WF', 'FL']\n   • Countries: ['Russia', 'Philippines', 'Fiji', 'Northern East Pacfic Rise', 'South Of Panama']...\n   • Alert Levels: ['Orange', 'Green']\n   ✅ Stored 100 REAL disaster events (3.6s)\n\n2. Ingesting Supply Chain News...\n\uD83D\uDCF0 Fetching REAL supply chain news from GNews API...\n   • API Key: cd8e55ad...c34d\n   • Searching: 'port congestion shipping'\n      • Status: 200\n      ✅ Found 0 articles\n   • Searching: 'supply chain disruption'\n      • Status: 200\n      ✅ Found 10 articles\n      • Sample: 'Continuous improvement in your supply chain has never been m...'\n   • Searching: 'maritime logistics'\n      • Status: 200\n      ✅ Found 10 articles\n      • Sample: 'Samsung heavy industries joins India's shipbuilding push wit...'\n   • Searching: 'shipping delays'\n      • Status: 200\n      ✅ Found 9 articles\n      • Sample: 'USPS deadline alert: Last chance to ship holiday cards and g...'\n   • Searching: 'container shipping'\n      • Status: 200\n      ✅ Found 10 articles\n      • Sample: 'Falling ocean shipping rates put carrier profits at risk, an...'\n✅ Processed 39 REAL news articles\n   • Sources: ['Wilmington News Journal', 'Fast Company', 'The Hindu Business Line']...\n   • Avg Sentiment: -0.33\n   ✅ Stored 39 REAL news articles (8.3s)\n\uD83C\uDF89 REAL DATA INGESTION COMPLETED! Total data points: 139\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA REAL DATA QUALITY ANALYSIS\n==================================================\n\uD83C\uDF2A️ GDACS Disaster Data:\n   • Total Events: 100\n   • Event Types: ['EQ', 'WF', 'TC', 'FL']\n   • Countries: ['Russia', 'Philippines', 'South Of Kermadec Islands']...\n   • Data Source: GDACS_API_REAL\n\n\uD83D\uDCF0 Supply Chain News:\n   • Total Articles: 39\n   • Sources: ['Wilmington News Journal', 'Fast Company', 'The Hindu Business Line']...\n   • Avg Sentiment: -0.33\n   • Data Source: GNEWS_API_REAL\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D PREVIEW OF REAL DATA COLLECTED\n==================================================\n\n\uD83C\uDF2A️ Recent Disaster Alerts:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>event_id</th><th>event_type</th><th>event_name</th><th>country</th><th>alert_level</th><th>start_date</th></tr></thead><tbody><tr><td>1001222</td><td>TC</td><td>Tropical Cyclone PRISCILLA-25</td><td>Mexico</td><td>Green</td><td>2025-10-04T21:00:00Z</td></tr><tr><td>1503491</td><td>EQ</td><td>Earthquake in Fiji</td><td>Fiji</td><td>Green</td><td>2025-10-04T18:50:54Z</td></tr><tr><td>1503487</td><td>EQ</td><td>Earthquake in Russia</td><td>Russia</td><td>Green</td><td>2025-10-04T17:43:53Z</td></tr><tr><td>1503482</td><td>EQ</td><td>Earthquake in Off East Coast Of Kamchatka</td><td>Off East Coast Of Kamchatka</td><td>Green</td><td>2025-10-04T17:38:01Z</td></tr><tr><td>1503467</td><td>EQ</td><td>Earthquake in Japan</td><td>Japan</td><td>Green</td><td>2025-10-04T15:21:09Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1001222",
         "TC",
         "Tropical Cyclone PRISCILLA-25",
         "Mexico",
         "Green",
         "2025-10-04T21:00:00Z"
        ],
        [
         "1503491",
         "EQ",
         "Earthquake in Fiji",
         "Fiji",
         "Green",
         "2025-10-04T18:50:54Z"
        ],
        [
         "1503487",
         "EQ",
         "Earthquake in Russia",
         "Russia",
         "Green",
         "2025-10-04T17:43:53Z"
        ],
        [
         "1503482",
         "EQ",
         "Earthquake in Off East Coast Of Kamchatka",
         "Off East Coast Of Kamchatka",
         "Green",
         "2025-10-04T17:38:01Z"
        ],
        [
         "1503467",
         "EQ",
         "Earthquake in Japan",
         "Japan",
         "Green",
         "2025-10-04T15:21:09Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "event_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "event_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "event_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "alert_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "start_date",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCF0 Recent Supply Chain News:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>article_id</th><th>title</th><th>source</th><th>sentiment_score</th><th>published_at</th></tr></thead><tbody><tr><td>REAL_NEWS_29_1759611728</td><td>Falling ocean shipping rates put carrier profits at risk, analysts say</td><td>The Economic Times</td><td>-0.9</td><td>2025-10-04T05:01:00Z</td></tr><tr><td>REAL_NEWS_30_1759611728</td><td>China eyes Arctic shortcut as top container lines stay away</td><td>The Economic Times</td><td>0.0</td><td>2025-10-04T04:36:00Z</td></tr><tr><td>REAL_NEWS_31_1759611728</td><td>Falling ocean shipping rates put carrier profits at risk, analysts say</td><td>Reuters</td><td>0.0</td><td>2025-10-03T18:37:38Z</td></tr><tr><td>REAL_NEWS_32_1759611728</td><td>LNG row splits Europe as US challenges net-zero shipping deal</td><td>Euractiv</td><td>-0.3</td><td>2025-10-01T04:00:19Z</td></tr><tr><td>REAL_NEWS_33_1759611728</td><td>Global container shipping lines making waves</td><td>The Hindu Business Line</td><td>0.0</td><td>2025-09-30T16:05:59Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "REAL_NEWS_29_1759611728",
         "Falling ocean shipping rates put carrier profits at risk, analysts say",
         "The Economic Times",
         -0.9,
         "2025-10-04T05:01:00Z"
        ],
        [
         "REAL_NEWS_30_1759611728",
         "China eyes Arctic shortcut as top container lines stay away",
         "The Economic Times",
         0.0,
         "2025-10-04T04:36:00Z"
        ],
        [
         "REAL_NEWS_31_1759611728",
         "Falling ocean shipping rates put carrier profits at risk, analysts say",
         "Reuters",
         0.0,
         "2025-10-03T18:37:38Z"
        ],
        [
         "REAL_NEWS_32_1759611728",
         "LNG row splits Europe as US challenges net-zero shipping deal",
         "Euractiv",
         -0.3,
         "2025-10-01T04:00:19Z"
        ],
        [
         "REAL_NEWS_33_1759611728",
         "Global container shipping lines making waves",
         "The Hindu Business Line",
         0.0,
         "2025-09-30T16:05:59Z"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "article_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sentiment_score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "published_at",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration updated with REAL data ingestion results\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83C\uDF89 REAL DATA INGESTION COMPLETED!\n\n\uD83D\uDCCA REAL DATA SUMMARY:\n• Disaster Alerts: 100 events\n• News Articles: 39 articles\n• Data Source: ✅ REAL APIs ONLY\n• Sample Data: ❌ NOT USED\n• Data Integrity: ✅ MAINTAINED\n\n\uD83D\uDD27 API PERFORMANCE:\n• GDACS API: ✅ DATA \n• GNews API: ✅ DATA\n\n\uD83D\uDCC8 NEXT STEPS:\n• Proceed to Notebook 3 for Feature Engineering\n• Even with limited data, we can build the ML pipeline\n• Real-world data scenarios include empty/limited responses\n• System designed for real production use cases\n\n\uD83D\uDCA1 PRODUCTION READY:\n• No synthetic data contamination\n• Real API error handling\n• Empty dataset management\n• Production-grade data pipeline\n\n"
     ]
    }
   ],
   "source": [
    "%run ./02_Data_Ingestion_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f575dcf1-f4ab-4f4a-9a62-e16a65cdd589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment imported from Notebook 2\n"
     ]
    }
   ],
   "source": [
    "# Additional imports for feature engineering\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import udf, col, avg, min, max, count, when, lit\n",
    "from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n",
    "from geopy.distance import geodesic\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"✅ Environment imported from Notebook 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb6358f6-02ad-4a6d-9419-5273db44f5b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D DATA QUALITY CHECK\n==================================================\n\uD83C\uDF2A️ GDACS Disaster Data:\n   • Total Events: 100\n   • Event Types: TC, EQ, WF, FL\n   • Data Source: GDACS_API_REAL\n   • Null Coordinates: 0\n\n\uD83D\uDCF0 Supply Chain News:\n   • Total Articles: 39\n   • Sources: Wilmington News Journal, Fast Company, The Hindu Business Line, The Economic Times, NDTV Profit...\n   • Data Source: GNEWS_API_REAL\n   • Avg Sentiment: -0.331\n   • Null Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "def check_data_quality():\n",
    "    \"\"\"Check quality of ingested data\"\"\"\n",
    "    print(\"\uD83D\uDD0D DATA QUALITY CHECK\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check GDACS data\n",
    "    gdacs_df = spark.table(\"supply_chain_analysis.bronze_gdacs_alerts\")\n",
    "    gdacs_stats = {\n",
    "        'total_events': gdacs_df.count(),\n",
    "        'event_types': [row['event_type'] for row in gdacs_df.select(\"event_type\").distinct().collect()],\n",
    "        'data_source': gdacs_df.select(\"data_source\").first()[0],\n",
    "        'null_coordinates': gdacs_df.filter(col(\"latitude\").isNull() | col(\"longitude\").isNull()).count()\n",
    "    }\n",
    "    \n",
    "    print(\"\uD83C\uDF2A️ GDACS Disaster Data:\")\n",
    "    print(f\"   • Total Events: {gdacs_stats['total_events']}\")\n",
    "    print(f\"   • Event Types: {', '.join(gdacs_stats['event_types'])}\")\n",
    "    print(f\"   • Data Source: {gdacs_stats['data_source']}\")\n",
    "    print(f\"   • Null Coordinates: {gdacs_stats['null_coordinates']}\")\n",
    "    \n",
    "    # Check News data\n",
    "    news_df = spark.table(\"supply_chain_analysis.bronze_supply_chain_news\")\n",
    "    news_stats = {\n",
    "        'total_articles': news_df.count(),\n",
    "        'sources': [row['source'] for row in news_df.select(\"source\").distinct().collect()],\n",
    "        'data_source': news_df.select(\"data_source\").first()[0],\n",
    "        'null_sentiment': news_df.filter(col(\"sentiment_score\").isNull()).count(),\n",
    "        'avg_sentiment': news_df.agg(avg(\"sentiment_score\")).collect()[0][0] or 0.0\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\uD83D\uDCF0 Supply Chain News:\")\n",
    "    print(f\"   • Total Articles: {news_stats['total_articles']}\")\n",
    "    print(f\"   • Sources: {', '.join(news_stats['sources'][:5])}{'...' if len(news_stats['sources']) > 5 else ''}\")\n",
    "    print(f\"   • Data Source: {news_stats['data_source']}\")\n",
    "    print(f\"   • Avg Sentiment: {news_stats['avg_sentiment']:.3f}\")\n",
    "    print(f\"   • Null Sentiment: {news_stats['null_sentiment']}\")\n",
    "    \n",
    "    return gdacs_stats, news_stats\n",
    "\n",
    "gdacs_stats, news_stats = check_data_quality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9428edcc-9504-49bb-93f2-5fb615576fba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD04 Creating Silver GDACS Table...\n✅ Silver GDACS table created with 100 enhanced records\n\uD83D\uDD04 Creating Silver News Table...\n✅ Silver News table created with 39 enhanced records\n"
     ]
    }
   ],
   "source": [
    "# Create silver GDACS table with risk calculations\n",
    "print(\"\uD83D\uDD04 Creating Silver GDACS Table...\")\n",
    "\n",
    "silver_gdacs_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    event_id,\n",
    "    event_type,\n",
    "    event_name,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    severity,\n",
    "    country,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    alert_level,\n",
    "    COALESCE(population_affected, 0) as population_affected,\n",
    "    insert_timestamp,\n",
    "    data_source,\n",
    "    -- Enhanced risk features\n",
    "    CASE \n",
    "        WHEN alert_level = 'Red' THEN 1.0\n",
    "        WHEN alert_level = 'Orange' THEN 0.7\n",
    "        WHEN alert_level = 'Yellow' THEN 0.4\n",
    "        ELSE 0.1\n",
    "    END as severity_score,\n",
    "    \n",
    "    CASE \n",
    "        WHEN event_type IN ('EQ', 'TC') THEN 1.0  -- Earthquake, Tropical Cyclone (high impact)\n",
    "        WHEN event_type IN ('FL', 'VO') THEN 0.8  -- Flood, Volcano (medium-high impact)\n",
    "        WHEN event_type = 'WF' THEN 0.6           -- Wildfire (medium impact)\n",
    "        WHEN event_type = 'DR' THEN 0.5           -- Drought (medium-low impact)\n",
    "        ELSE 0.4                                  -- Other events\n",
    "    END as impact_multiplier,\n",
    "    \n",
    "    -- Population impact score (normalized)\n",
    "    LEAST(COALESCE(population_affected, 0) / 1000000.0, 1.0) as population_impact,\n",
    "    \n",
    "    -- Combined risk score\n",
    "    (CASE \n",
    "        WHEN alert_level = 'Red' THEN 1.0\n",
    "        WHEN alert_level = 'Orange' THEN 0.7\n",
    "        WHEN alert_level = 'Yellow' THEN 0.4\n",
    "        ELSE 0.1\n",
    "    END * \n",
    "    CASE \n",
    "        WHEN event_type IN ('EQ', 'TC') THEN 1.0\n",
    "        WHEN event_type IN ('FL', 'VO') THEN 0.8\n",
    "        WHEN event_type = 'WF' THEN 0.6\n",
    "        WHEN event_type = 'DR' THEN 0.5\n",
    "        ELSE 0.4\n",
    "    END * \n",
    "    GREATEST(0.1, LEAST(COALESCE(population_affected, 0) / 1000000.0, 1.0))) as calculated_risk_score,\n",
    "    \n",
    "    -- Duration impact (events lasting longer are higher risk)\n",
    "    DATEDIFF(end_date, start_date) as duration_days\n",
    "    \n",
    "FROM supply_chain_analysis.bronze_gdacs_alerts\n",
    "WHERE latitude IS NOT NULL \n",
    "  AND longitude IS NOT NULL\n",
    "  AND start_date IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "silver_gdacs_df.write.mode(\"overwrite\").saveAsTable(\"supply_chain_analysis.silver_gdacs_alerts\")\n",
    "print(f\"✅ Silver GDACS table created with {silver_gdacs_df.count()} enhanced records\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Create silver news table with improved sentiment\n",
    "print(\"\uD83D\uDD04 Creating Silver News Table...\")\n",
    "\n",
    "silver_news_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    article_id,\n",
    "    title,\n",
    "    description,\n",
    "    content,\n",
    "    published_at,\n",
    "    source,\n",
    "    url,\n",
    "    keywords,\n",
    "    -- Handle null sentiment scores\n",
    "    CASE \n",
    "        WHEN sentiment_score IS NULL THEN 0.0\n",
    "        ELSE sentiment_score \n",
    "    END as sentiment_score,\n",
    "    insert_timestamp,\n",
    "    data_source,\n",
    "    -- Enhanced features\n",
    "    CASE \n",
    "        WHEN sentiment_score < -0.5 THEN 'High Negative Impact'\n",
    "        WHEN sentiment_score < -0.2 THEN 'Medium Negative Impact'\n",
    "        WHEN sentiment_score > 0.5 THEN 'High Positive Impact'\n",
    "        WHEN sentiment_score > 0.2 THEN 'Medium Positive Impact'\n",
    "        ELSE 'Neutral/Low Impact'\n",
    "    END as impact_category,\n",
    "    \n",
    "    ABS(sentiment_score) as impact_magnitude,\n",
    "    \n",
    "    -- News risk score (negative sentiment = higher supply chain risk)\n",
    "    GREATEST(0.0, -sentiment_score) as news_risk_score,\n",
    "    \n",
    "    -- Recency score (newer articles have higher weight)\n",
    "    CASE \n",
    "        WHEN published_at >= current_timestamp() - INTERVAL 1 day THEN 1.0\n",
    "        WHEN published_at >= current_timestamp() - INTERVAL 3 days THEN 0.7\n",
    "        WHEN published_at >= current_timestamp() - INTERVAL 7 days THEN 0.4\n",
    "        ELSE 0.1\n",
    "    END as recency_weight\n",
    "    \n",
    "FROM supply_chain_analysis.bronze_supply_chain_news\n",
    "WHERE published_at IS NOT NULL\n",
    "  AND title IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "silver_news_df.write.mode(\"overwrite\").saveAsTable(\"supply_chain_analysis.silver_supply_chain_news\")\n",
    "print(f\"✅ Silver News table created with {silver_news_df.count()} enhanced records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf4549ba-0fcc-428e-9867-af99344e5c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Geospatial distance function registered\n"
     ]
    }
   ],
   "source": [
    "# Distance calculation UDF\n",
    "@udf(returnType=DoubleType())\n",
    "def calculate_distance_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate distance between two points in kilometers\"\"\"\n",
    "    try:\n",
    "        return geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "    except:\n",
    "        return 99999.0  # Large distance for errors\n",
    "\n",
    "# Register the UDF\n",
    "spark.udf.register(\"calculate_distance_km\", calculate_distance_km)\n",
    "\n",
    "print(\"✅ Geospatial distance function registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19e596ea-96fd-4a48-ba3e-3b545de3a0c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCB Ports Table Schema:\n   • port_name: StringType()\n   • latitude: DoubleType()\n   • longitude: DoubleType()\n   • country: StringType()\n   • port_size: StringType()\n   • capacity_rating: StringType()\n   • region: StringType()\n\n\uD83D\uDCCA Sample Ports Data:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>port_name</th><th>latitude</th><th>longitude</th><th>country</th><th>port_size</th><th>capacity_rating</th><th>region</th></tr></thead><tbody><tr><td>Hamburg</td><td>53.5511</td><td>9.9937</td><td>Germany</td><td>Major</td><td>High</td><td>Europe</td></tr><tr><td>Felixstowe</td><td>51.9617</td><td>1.3513</td><td>UK</td><td>Major</td><td>Medium</td><td>Europe</td></tr><tr><td>Valencia</td><td>39.4699</td><td>-0.3763</td><td>Spain</td><td>Major</td><td>Medium</td><td>Europe</td></tr><tr><td>Los Angeles</td><td>33.7175</td><td>-118.2675</td><td>USA</td><td>Major</td><td>High</td><td>North America</td></tr><tr><td>Long Beach</td><td>33.7623</td><td>-118.1954</td><td>USA</td><td>Major</td><td>High</td><td>North America</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Hamburg",
         53.5511,
         9.9937,
         "Germany",
         "Major",
         "High",
         "Europe"
        ],
        [
         "Felixstowe",
         51.9617,
         1.3513,
         "UK",
         "Major",
         "Medium",
         "Europe"
        ],
        [
         "Valencia",
         39.4699,
         -0.3763,
         "Spain",
         "Major",
         "Medium",
         "Europe"
        ],
        [
         "Los Angeles",
         33.7175,
         -118.2675,
         "USA",
         "Major",
         "High",
         "North America"
        ],
        [
         "Long Beach",
         33.7623,
         -118.1954,
         "USA",
         "Major",
         "High",
         "North America"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "port_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "port_size",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "capacity_rating",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "region",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the actual schema of our ports table\n",
    "ports_df = spark.table(\"supply_chain_analysis.dim_ports\")\n",
    "print(\"\uD83D\uDCCB Ports Table Schema:\")\n",
    "for field in ports_df.schema.fields:\n",
    "    print(f\"   • {field.name}: {field.dataType}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\n\uD83D\uDCCA Sample Ports Data:\")\n",
    "display(ports_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a3eb4f-ac9a-4f14-9a30-21cdfcb78675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83C\uDF10 CALCULATING PORT RISK SCORES...\n   • Ports to analyze: 19\n   • Active disasters: 100\n   • News articles: 39\n   \uD83D\uDD0D Analyzing Hamburg...\n   \uD83D\uDD0D Analyzing Felixstowe...\n   \uD83D\uDD0D Analyzing Valencia...\n   \uD83D\uDD0D Analyzing Los Angeles...\n   \uD83D\uDD0D Analyzing Long Beach...\n   \uD83D\uDD0D Analyzing New York...\n   \uD83D\uDD0D Analyzing Savannah...\n   \uD83D\uDD0D Analyzing Vancouver...\n   \uD83D\uDD0D Analyzing Jebel Ali...\n   \uD83D\uDD0D Analyzing Salalah...\n   \uD83D\uDD0D Analyzing Shanghai...\n   \uD83D\uDD0D Analyzing Singapore...\n   \uD83D\uDD0D Analyzing Shenzhen...\n   \uD83D\uDD0D Analyzing Ningbo-Zhoushan...\n   \uD83D\uDD0D Analyzing Hong Kong...\n   \uD83D\uDD0D Analyzing Busan...\n   \uD83D\uDD0D Analyzing Qingdao...\n   \uD83D\uDD0D Analyzing Rotterdam...\n   \uD83D\uDD0D Analyzing Antwerp...\n✅ Risk analysis completed for 19 ports\n"
     ]
    }
   ],
   "source": [
    "# MAGIC %md\n",
    "## \uD83C\uDFAF Port Risk Analysis - FIXED TYPE CONVERSION\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def calculate_port_risks():\n",
    "    \"\"\"Calculate comprehensive risk scores for all major ports - FIXED TYPE CONVERSION\"\"\"\n",
    "    \n",
    "    print(\"\uD83C\uDF10 CALCULATING PORT RISK SCORES...\")\n",
    "    \n",
    "    # Load data\n",
    "    ports_df = spark.table(\"supply_chain_analysis.dim_ports\")\n",
    "    disasters_df = spark.table(\"supply_chain_analysis.silver_gdacs_alerts\")\n",
    "    news_df = spark.table(\"supply_chain_analysis.silver_supply_chain_news\")\n",
    "    \n",
    "    print(f\"   • Ports to analyze: {ports_df.count()}\")\n",
    "    print(f\"   • Active disasters: {disasters_df.count()}\")\n",
    "    print(f\"   • News articles: {news_df.count()}\")\n",
    "    \n",
    "    port_risks = []\n",
    "    \n",
    "    # Calculate risk for each port\n",
    "    for port_row in ports_df.collect():\n",
    "        port_name = port_row.port_name\n",
    "        port_lat = float(port_row.latitude)  # Convert to float\n",
    "        port_lon = float(port_row.longitude)  # Convert to float\n",
    "        \n",
    "        print(f\"   \uD83D\uDD0D Analyzing {port_name}...\")\n",
    "        \n",
    "        # 1. DISASTER PROXIMITY RISK\n",
    "        disaster_risk = 0.0\n",
    "        nearby_disasters = []\n",
    "        \n",
    "        for disaster_row in disasters_df.collect():\n",
    "            disaster_lat = float(disaster_row.latitude)  # Convert to float\n",
    "            disaster_lon = float(disaster_row.longitude)  # Convert to float\n",
    "            disaster_risk_score = float(disaster_row.calculated_risk_score)  # Convert to float\n",
    "            \n",
    "            # Calculate distance using geopy directly\n",
    "            try:\n",
    "                distance = geodesic((port_lat, port_lon), (disaster_lat, disaster_lon)).kilometers\n",
    "            except:\n",
    "                distance = 99999.0\n",
    "            \n",
    "            # Risk decreases with distance, influenced by disaster severity\n",
    "            if distance < 1000:  # Within 1000km\n",
    "                proximity_factor = 1.0 - (distance / 1000.0)\n",
    "                if proximity_factor < 0.0:\n",
    "                    proximity_factor = 0.0\n",
    "                    \n",
    "                disaster_contribution = disaster_risk_score * proximity_factor\n",
    "                if disaster_contribution > disaster_risk:\n",
    "                    disaster_risk = disaster_contribution\n",
    "                \n",
    "                if distance < 500:  # Track nearby disasters\n",
    "                    nearby_disasters.append({\n",
    "                        'event_type': disaster_row.event_type,\n",
    "                        'event_name': disaster_row.event_name,\n",
    "                        'distance_km': int(distance),\n",
    "                        'risk_score': disaster_risk_score,\n",
    "                        'alert_level': disaster_row.alert_level\n",
    "                    })\n",
    "        \n",
    "        # 2. NEWS SENTIMENT RISK - FIXED VERSION\n",
    "        news_risk = 0.0\n",
    "        port_news_count = 0\n",
    "        \n",
    "        # Check for news mentioning this port - FIXED: No generator in any()\n",
    "        port_news_list = news_df.collect()\n",
    "        port_related_articles = []\n",
    "        \n",
    "        for news_row in port_news_list:\n",
    "            title = news_row.title or \"\"\n",
    "            description = news_row.description or \"\"\n",
    "            content = news_row.content or \"\"\n",
    "            keywords = news_row.keywords or []\n",
    "            \n",
    "            # FIXED: Check if port is mentioned without using generator in any()\n",
    "            port_mentioned = False\n",
    "            \n",
    "            # Check title, description, content\n",
    "            if (port_name.lower() in title.lower() or \n",
    "                port_name.lower() in description.lower() or \n",
    "                port_name.lower() in content.lower()):\n",
    "                port_mentioned = True\n",
    "            \n",
    "            # Check keywords using explicit loop instead of generator\n",
    "            if not port_mentioned and keywords:\n",
    "                for kw in keywords:\n",
    "                    if port_name.lower() in str(kw).lower():\n",
    "                        port_mentioned = True\n",
    "                        break\n",
    "            \n",
    "            if port_mentioned:\n",
    "                port_related_articles.append(news_row)\n",
    "        \n",
    "        port_news_count = len(port_related_articles)\n",
    "        \n",
    "        if port_news_count > 0:\n",
    "            total_news_risk = 0.0\n",
    "            for article in port_related_articles:\n",
    "                total_news_risk += float(article.news_risk_score)  # Convert to float\n",
    "                \n",
    "            avg_news_risk = total_news_risk / port_news_count\n",
    "            # Scale news impact based on volume and sentiment\n",
    "            news_multiplier = 1.0 + (port_news_count / 10.0)\n",
    "            if news_multiplier > 2.0:\n",
    "                news_multiplier = 2.0\n",
    "                \n",
    "            news_risk_temp = avg_news_risk * news_multiplier\n",
    "            if news_risk_temp > 1.0:\n",
    "                news_risk = 1.0\n",
    "            else:\n",
    "                news_risk = news_risk_temp\n",
    "        \n",
    "        # 3. PORT CAPACITY RISK (use capacity_rating instead of port_size)\n",
    "        capacity_risk_map = {\n",
    "            \"Very High\": 0.1,  # Best infrastructure, lowest risk\n",
    "            \"High\": 0.2,\n",
    "            \"Medium\": 0.4,\n",
    "            \"Low\": 0.6         # Poor infrastructure, higher risk\n",
    "        }\n",
    "        capacity_risk = capacity_risk_map.get(str(port_row.capacity_rating), 0.3)  # Ensure string\n",
    "        \n",
    "        # 4. REGIONAL RISK FACTOR\n",
    "        regional_risk = {\n",
    "            \"Asia\": 0.3,        # High traffic, but good infrastructure\n",
    "            \"Europe\": 0.2,       # Good infrastructure\n",
    "            \"North America\": 0.25,\n",
    "            \"Middle East\": 0.4,  # Geopolitical factors\n",
    "            \"Oceania\": 0.3\n",
    "        }.get(str(port_row.region), 0.35)  # Ensure string\n",
    "        \n",
    "        # 5. PORT SIZE FACTOR (additional factor based on port_size)\n",
    "        size_risk = {\n",
    "            \"Major\": 0.2,       # Major ports have better infrastructure\n",
    "            \"Large\": 0.3,\n",
    "            \"Medium\": 0.5\n",
    "        }.get(str(port_row.port_size), 0.4)  # Ensure string\n",
    "        \n",
    "        # 6. CALCULATE OVERALL RISK (weighted average)\n",
    "        overall_risk = (\n",
    "            disaster_risk * 0.35 +      # 35% disaster proximity\n",
    "            news_risk * 0.25 +          # 25% news sentiment  \n",
    "            capacity_risk * 0.20 +      # 20% port capacity rating\n",
    "            regional_risk * 0.15 +      # 15% regional factors\n",
    "            size_risk * 0.05            # 5% port size\n",
    "        )\n",
    "        \n",
    "        # Clamp between 0 and 1\n",
    "        if overall_risk > 1.0:\n",
    "            overall_risk = 1.0\n",
    "        elif overall_risk < 0.0:\n",
    "            overall_risk = 0.0\n",
    "        \n",
    "        # Determine risk level\n",
    "        if overall_risk > 0.7:\n",
    "            risk_level = \"HIGH\"\n",
    "        elif overall_risk > 0.4:\n",
    "            risk_level = \"MEDIUM\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "        \n",
    "        # Use the actual columns that exist in our table\n",
    "        port_risks.append((\n",
    "            port_name,\n",
    "            port_lat,  # Already converted to float\n",
    "            port_lon,  # Already converted to float\n",
    "            str(port_row.country),  # Ensure string\n",
    "            str(port_row.region),   # Ensure string\n",
    "            str(port_row.port_size), # Ensure string\n",
    "            str(port_row.capacity_rating),  # Use actual capacity_rating column\n",
    "            overall_risk,\n",
    "            risk_level,\n",
    "            disaster_risk,\n",
    "            news_risk,\n",
    "            capacity_risk,\n",
    "            regional_risk,\n",
    "            size_risk,\n",
    "            port_news_count,\n",
    "            len(nearby_disasters),\n",
    "            json.dumps(nearby_disasters[:5]),  # Top 5 nearby disasters\n",
    "            datetime.now()\n",
    "        ))\n",
    "    \n",
    "    # Create risk schema with correct columns\n",
    "    risk_schema = StructType([\n",
    "        StructField(\"port_name\", StringType(), True),\n",
    "        StructField(\"latitude\", DoubleType(), True),\n",
    "        StructField(\"longitude\", DoubleType(), True),\n",
    "        StructField(\"country\", StringType(), True),\n",
    "        StructField(\"region\", StringType(), True),\n",
    "        StructField(\"port_size\", StringType(), True),\n",
    "        StructField(\"capacity_rating\", StringType(), True),  # Use actual column name\n",
    "        StructField(\"overall_risk\", DoubleType(), True),\n",
    "        StructField(\"risk_level\", StringType(), True),\n",
    "        StructField(\"disaster_risk\", DoubleType(), True),\n",
    "        StructField(\"news_risk\", DoubleType(), True),\n",
    "        StructField(\"capacity_risk\", DoubleType(), True),\n",
    "        StructField(\"regional_risk\", DoubleType(), True),\n",
    "        StructField(\"size_risk\", DoubleType(), True),\n",
    "        StructField(\"news_mentions\", IntegerType(), True),\n",
    "        StructField(\"nearby_disasters_count\", IntegerType(), True),\n",
    "        StructField(\"nearby_disasters_json\", StringType(), True),\n",
    "        StructField(\"calculated_at\", TimestampType(), True)\n",
    "    ])\n",
    "    \n",
    "    risks_df = spark.createDataFrame(port_risks, risk_schema)\n",
    "    risks_df.write.mode(\"overwrite\").saveAsTable(\"supply_chain_analysis.port_risk_scores\")\n",
    "    \n",
    "    print(f\"✅ Risk analysis completed for {len(port_risks)} ports\")\n",
    "    return risks_df\n",
    "\n",
    "# Calculate all port risks\n",
    "port_risks_df = calculate_port_risks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7768fc9f-004d-4d34-a5fb-01092e59831c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD2C MLFLOW EXPERIMENT RESULTS:\n   • Total Ports Analyzed: 19\n   • Average Risk Score: 0.139\n   • Risk Distribution: 0 High, 0 Medium, 19 Low\n   • High Risk Ports: 0.0%\n   • Run ID: b3d4beeb9cfa4f7c89507c34f74aeeee\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow experiment\n",
    "with mlflow.start_run(run_name=\"supply_chain_risk_analysis\"):\n",
    "    \n",
    "    # Log dataset information\n",
    "    total_ports = port_risks_df.count()\n",
    "    high_risk_ports = port_risks_df.filter(col(\"overall_risk\") > 0.7).count()\n",
    "    medium_risk_ports = port_risks_df.filter((col(\"overall_risk\") > 0.4) & (col(\"overall_risk\") <= 0.7)).count()\n",
    "    low_risk_ports = port_risks_df.filter(col(\"overall_risk\") <= 0.4).count()\n",
    "    \n",
    "    # Calculate risk statistics\n",
    "    risk_stats = port_risks_df.select(\n",
    "        avg(\"overall_risk\").alias(\"avg_risk\"),\n",
    "        min(\"overall_risk\").alias(\"min_risk\"), \n",
    "        max(\"overall_risk\").alias(\"max_risk\"),\n",
    "        avg(\"disaster_risk\").alias(\"avg_disaster_risk\"),\n",
    "        avg(\"news_risk\").alias(\"avg_news_risk\"),\n",
    "        avg(\"capacity_risk\").alias(\"avg_capacity_risk\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"total_ports_analyzed\": total_ports,\n",
    "        \"gdacs_events\": gdacs_stats['total_events'],\n",
    "        \"news_articles\": news_stats['total_articles'],\n",
    "        \"data_sources\": f\"GDACS: {gdacs_stats['data_source']}, News: {news_stats['data_source']}\",\n",
    "        \"risk_calculation_method\": \"Weighted multi-factor analysis\"\n",
    "    })\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"average_port_risk\": risk_stats.avg_risk or 0.0,\n",
    "        \"min_port_risk\": risk_stats.min_risk or 0.0,\n",
    "        \"max_port_risk\": risk_stats.max_risk or 0.0,\n",
    "        \"high_risk_ports\": high_risk_ports,\n",
    "        \"medium_risk_ports\": medium_risk_ports,\n",
    "        \"low_risk_ports\": low_risk_ports,\n",
    "        \"average_disaster_risk\": risk_stats.avg_disaster_risk or 0.0,\n",
    "        \"average_news_risk\": risk_stats.avg_news_risk or 0.0,\n",
    "        \"average_capacity_risk\": risk_stats.avg_capacity_risk or 0.0\n",
    "    })\n",
    "    \n",
    "    # Log risk distribution\n",
    "    risk_distribution = {\n",
    "        \"high_risk_percentage\": (high_risk_ports / total_ports * 100) if total_ports > 0 else 0,\n",
    "        \"medium_risk_percentage\": (medium_risk_ports / total_ports * 100) if total_ports > 0 else 0,\n",
    "        \"low_risk_percentage\": (low_risk_ports / total_ports * 100) if total_ports > 0 else 0\n",
    "    }\n",
    "    \n",
    "    mlflow.log_metrics(risk_distribution)\n",
    "    \n",
    "    print(\"\uD83D\uDD2C MLFLOW EXPERIMENT RESULTS:\")\n",
    "    print(f\"   • Total Ports Analyzed: {total_ports}\")\n",
    "    print(f\"   • Average Risk Score: {risk_stats.avg_risk:.3f}\")\n",
    "    print(f\"   • Risk Distribution: {high_risk_ports} High, {medium_risk_ports} Medium, {low_risk_ports} Low\")\n",
    "    print(f\"   • High Risk Ports: {risk_distribution['high_risk_percentage']:.1f}%\")\n",
    "    print(f\"   • Run ID: {mlflow.active_run().info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43b507d5-8606-4d5d-8079-898d5299e259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA SUPPLY CHAIN RISK DASHBOARD\n============================================================\n\n\uD83D\uDD34 TOP 10 HIGHEST RISK PORTS:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>port_name</th><th>country</th><th>region</th><th>risk_level</th><th>risk_score</th><th>disaster_risk</th><th>news_risk</th><th>nearby_disasters_count</th><th>news_mentions</th></tr></thead><tbody><tr><td>Shenzhen</td><td>China</td><td>Asia</td><td>LOW</td><td>0.29</td><td>0.047</td><td>0.715</td><td>1</td><td>1</td></tr><tr><td>Hong Kong</td><td>China</td><td>Asia</td><td>LOW</td><td>0.277</td><td>0.048</td><td>0.66</td><td>1</td><td>1</td></tr><tr><td>Long Beach</td><td>USA</td><td>North America</td><td>LOW</td><td>0.266</td><td>0.0</td><td>0.715</td><td>0</td><td>1</td></tr><tr><td>Shanghai</td><td>China</td><td>Asia</td><td>LOW</td><td>0.24</td><td>0.0</td><td>0.66</td><td>0</td><td>1</td></tr><tr><td>Salalah</td><td>Oman</td><td>Middle East</td><td>LOW</td><td>0.15</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td></tr><tr><td>Qingdao</td><td>China</td><td>Asia</td><td>LOW</td><td>0.135</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td></tr><tr><td>Vancouver</td><td>Canada</td><td>North America</td><td>LOW</td><td>0.128</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td></tr><tr><td>Savannah</td><td>USA</td><td>North America</td><td>LOW</td><td>0.128</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td></tr><tr><td>Valencia</td><td>Spain</td><td>Europe</td><td>LOW</td><td>0.12</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td></tr><tr><td>Felixstowe</td><td>UK</td><td>Europe</td><td>LOW</td><td>0.12</td><td>0.0</td><td>0.0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Shenzhen",
         "China",
         "Asia",
         "LOW",
         0.29,
         0.047,
         0.715,
         1,
         1
        ],
        [
         "Hong Kong",
         "China",
         "Asia",
         "LOW",
         0.277,
         0.048,
         0.66,
         1,
         1
        ],
        [
         "Long Beach",
         "USA",
         "North America",
         "LOW",
         0.266,
         0.0,
         0.715,
         0,
         1
        ],
        [
         "Shanghai",
         "China",
         "Asia",
         "LOW",
         0.24,
         0.0,
         0.66,
         0,
         1
        ],
        [
         "Salalah",
         "Oman",
         "Middle East",
         "LOW",
         0.15,
         0.0,
         0.0,
         0,
         0
        ],
        [
         "Qingdao",
         "China",
         "Asia",
         "LOW",
         0.135,
         0.0,
         0.0,
         0,
         0
        ],
        [
         "Vancouver",
         "Canada",
         "North America",
         "LOW",
         0.128,
         0.0,
         0.0,
         0,
         0
        ],
        [
         "Savannah",
         "USA",
         "North America",
         "LOW",
         0.128,
         0.0,
         0.0,
         0,
         0
        ],
        [
         "Valencia",
         "Spain",
         "Europe",
         "LOW",
         0.12,
         0.0,
         0.0,
         0,
         0
        ],
        [
         "Felixstowe",
         "UK",
         "Europe",
         "LOW",
         0.12,
         0.0,
         0.0,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "port_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "risk_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "risk_score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "disaster_risk",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "news_risk",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "nearby_disasters_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "news_mentions",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83C\uDF0D RISK DISTRIBUTION BY REGION:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>region</th><th>total_ports</th><th>avg_risk</th><th>high_risk_ports</th><th>medium_risk_ports</th><th>low_risk_ports</th></tr></thead><tbody><tr><td>Asia</td><td>7</td><td>0.173</td><td>0</td><td>0</td><td>7</td></tr><tr><td>North America</td><td>5</td><td>0.139</td><td>0</td><td>0</td><td>5</td></tr><tr><td>Middle East</td><td>2</td><td>0.13</td><td>0</td><td>0</td><td>2</td></tr><tr><td>Europe</td><td>5</td><td>0.096</td><td>0</td><td>0</td><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Asia",
         7,
         0.173,
         0,
         0,
         7
        ],
        [
         "North America",
         5,
         0.139,
         0,
         0,
         5
        ],
        [
         "Middle East",
         2,
         0.13,
         0,
         0,
         2
        ],
        [
         "Europe",
         5,
         0.096,
         0,
         0,
         5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "total_ports",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_risk",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "high_risk_ports",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "medium_risk_ports",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "low_risk_ports",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83C\uDF2A️ DISASTER IMPACT ANALYSIS:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>event_type</th><th>event_count</th><th>avg_risk_score</th><th>avg_severity</th><th>countries_affected</th><th>avg_population_impact</th></tr></thead><tbody><tr><td>TC</td><td>5</td><td>0.034</td><td>0.340</td><td>4</td><td>0.000</td></tr><tr><td>EQ</td><td>41</td><td>0.010</td><td>0.100</td><td>17</td><td>0.000</td></tr><tr><td>FL</td><td>1</td><td>0.008</td><td>0.100</td><td>1</td><td>0.000</td></tr><tr><td>WF</td><td>53</td><td>0.006</td><td>0.100</td><td>3</td><td>0.000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "TC",
         5,
         "0.034",
         "0.340",
         4,
         "0.000"
        ],
        [
         "EQ",
         41,
         "0.010",
         "0.100",
         17,
         "0.000"
        ],
        [
         "FL",
         1,
         "0.008",
         "0.100",
         1,
         "0.000"
        ],
        [
         "WF",
         53,
         "0.006",
         "0.100",
         3,
         "0.000"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "event_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "event_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_risk_score",
         "type": "\"decimal(19,3)\""
        },
        {
         "metadata": "{}",
         "name": "avg_severity",
         "type": "\"decimal(5,3)\""
        },
        {
         "metadata": "{}",
         "name": "countries_affected",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_population_impact",
         "type": "\"decimal(15,3)\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCF0 NEWS SENTIMENT ANALYSIS:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>impact_category</th><th>article_count</th><th>avg_sentiment</th><th>avg_risk_score</th><th>unique_sources</th></tr></thead><tbody><tr><td>High Negative Impact</td><td>20</td><td>-0.683</td><td>0.683</td><td>17</td></tr><tr><td>Medium Negative Impact</td><td>2</td><td>-0.3</td><td>0.3</td><td>2</td></tr><tr><td>Neutral/Low Impact</td><td>14</td><td>0.0</td><td>0.0</td><td>12</td></tr><tr><td>Medium Positive Impact</td><td>3</td><td>0.45</td><td>0.0</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "High Negative Impact",
         20,
         -0.683,
         0.683,
         17
        ],
        [
         "Medium Negative Impact",
         2,
         -0.3,
         0.3,
         2
        ],
        [
         "Neutral/Low Impact",
         14,
         0.0,
         0.0,
         12
        ],
        [
         "Medium Positive Impact",
         3,
         0.45,
         0.0,
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "impact_category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "article_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "avg_sentiment",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_risk_score",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "unique_sources",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\uD83D\uDCCA SUPPLY CHAIN RISK DASHBOARD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Top 10 Highest Risk Ports\n",
    "print(\"\\n\uD83D\uDD34 TOP 10 HIGHEST RISK PORTS:\")\n",
    "top_risks = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    port_name, \n",
    "    country,\n",
    "    region,\n",
    "    risk_level,\n",
    "    ROUND(overall_risk, 3) as risk_score,\n",
    "    ROUND(disaster_risk, 3) as disaster_risk,\n",
    "    ROUND(news_risk, 3) as news_risk,\n",
    "    nearby_disasters_count,\n",
    "    news_mentions\n",
    "FROM supply_chain_analysis.port_risk_scores \n",
    "ORDER BY overall_risk DESC \n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "display(top_risks)\n",
    "\n",
    "# 2. Risk Distribution by Region\n",
    "print(\"\\n\uD83C\uDF0D RISK DISTRIBUTION BY REGION:\")\n",
    "regional_risks = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    region,\n",
    "    COUNT(*) as total_ports,\n",
    "    ROUND(AVG(overall_risk), 3) as avg_risk,\n",
    "    COUNT(CASE WHEN risk_level = 'HIGH' THEN 1 END) as high_risk_ports,\n",
    "    COUNT(CASE WHEN risk_level = 'MEDIUM' THEN 1 END) as medium_risk_ports,\n",
    "    COUNT(CASE WHEN risk_level = 'LOW' THEN 1 END) as low_risk_ports\n",
    "FROM supply_chain_analysis.port_risk_scores \n",
    "GROUP BY region\n",
    "ORDER BY avg_risk DESC\n",
    "\"\"\")\n",
    "display(regional_risks)\n",
    "\n",
    "# 3. Disaster Impact Analysis\n",
    "print(\"\\n\uD83C\uDF2A️ DISASTER IMPACT ANALYSIS:\")\n",
    "disaster_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    event_type,\n",
    "    COUNT(*) as event_count,\n",
    "    ROUND(AVG(calculated_risk_score), 3) as avg_risk_score,\n",
    "    ROUND(AVG(severity_score), 3) as avg_severity,\n",
    "    COUNT(DISTINCT country) as countries_affected,\n",
    "    ROUND(AVG(population_impact), 3) as avg_population_impact\n",
    "FROM supply_chain_analysis.silver_gdacs_alerts\n",
    "GROUP BY event_type\n",
    "ORDER BY avg_risk_score DESC\n",
    "\"\"\")\n",
    "display(disaster_analysis)\n",
    "\n",
    "# 4. News Sentiment Analysis\n",
    "print(\"\\n\uD83D\uDCF0 NEWS SENTIMENT ANALYSIS:\")\n",
    "sentiment_analysis = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    impact_category,\n",
    "    COUNT(*) as article_count,\n",
    "    ROUND(AVG(sentiment_score), 3) as avg_sentiment,\n",
    "    ROUND(AVG(news_risk_score), 3) as avg_risk_score,\n",
    "    COUNT(DISTINCT source) as unique_sources\n",
    "FROM supply_chain_analysis.silver_supply_chain_news\n",
    "GROUP BY impact_category\n",
    "ORDER BY avg_risk_score DESC\n",
    "\"\"\")\n",
    "display(sentiment_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca329b98-f04a-4f03-a5d6-4d92876d5a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD0D RISK FACTOR CORRELATION ANALYSIS\n==================================================\n\uD83D\uDCC8 Correlation with Overall Risk:\n   • Disaster Risk: 0.691\n   • News Risk: 0.951\n   • Capacity Risk: -0.107\n   • Regional Risk: 0.251\n   • Nearby Disasters Count: 0.705\n   • News Mentions: 0.666\n"
     ]
    }
   ],
   "source": [
    "print(\"\uD83D\uDD0D RISK FACTOR CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze how different factors contribute to overall risk\n",
    "risk_correlations = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    ROUND(CORR(overall_risk, disaster_risk), 3) as disaster_correlation,\n",
    "    ROUND(CORR(overall_risk, news_risk), 3) as news_correlation,\n",
    "    ROUND(CORR(overall_risk, capacity_risk), 3) as capacity_correlation,\n",
    "    ROUND(CORR(overall_risk, regional_risk), 3) as regional_correlation,\n",
    "    ROUND(CORR(overall_risk, nearby_disasters_count), 3) as disaster_count_correlation,\n",
    "    ROUND(CORR(overall_risk, news_mentions), 3) as news_mentions_correlation\n",
    "FROM supply_chain_analysis.port_risk_scores\n",
    "\"\"\")\n",
    "\n",
    "corr_results = risk_correlations.collect()[0]\n",
    "print(\"\uD83D\uDCC8 Correlation with Overall Risk:\")\n",
    "print(f\"   • Disaster Risk: {corr_results.disaster_correlation or 0:.3f}\")\n",
    "print(f\"   • News Risk: {corr_results.news_correlation or 0:.3f}\")\n",
    "print(f\"   • Capacity Risk: {corr_results.capacity_correlation or 0:.3f}\")\n",
    "print(f\"   • Regional Risk: {corr_results.regional_correlation or 0:.3f}\")\n",
    "print(f\"   • Nearby Disasters Count: {corr_results.disaster_count_correlation or 0:.3f}\")\n",
    "print(f\"   • News Mentions: {corr_results.news_mentions_correlation or 0:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f6aa70f-29bb-4f99-bc91-e6fcbcf91d6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration updated with feature engineering results\n"
     ]
    }
   ],
   "source": [
    "# Update configuration with feature engineering results\n",
    "config_path = \"/dbfs/FileStore/supply_chain/config.json\"\n",
    "\n",
    "try:\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Get MLflow run ID safely\n",
    "    active_run = mlflow.active_run()\n",
    "    mlflow_run_id = active_run.info.run_id if active_run else \"no_active_run\"\n",
    "    \n",
    "    config['feature_engineering_completed'] = True\n",
    "    config['feature_engineering_timestamp'] = datetime.now().isoformat()\n",
    "    config['ports_analyzed'] = port_risks_df.count()\n",
    "    config['high_risk_ports'] = high_risk_ports\n",
    "    config['medium_risk_ports'] = medium_risk_ports\n",
    "    config['low_risk_ports'] = low_risk_ports\n",
    "    config['average_risk_score'] = risk_stats.avg_risk or 0.0\n",
    "    config['mlflow_run_id_risk_analysis'] = mlflow_run_id\n",
    "    \n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"✅ Configuration updated with feature engineering results\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to update configuration: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a189867-62de-4be4-a93d-bfc3db5296f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83C\uDF89 SATURDAY WORK COMPLETED SUCCESSFULLY!\n\n\uD83D\uDCCA REAL DATA PROCESSING SUMMARY:\n• Disaster Events: 100 events (4 types)\n• News Articles: 39 articles (30 sources)  \n• Ports Analyzed: 19 major global ports\n• Data Sources: ✅ REAL APIs ONLY\n\n\uD83D\uDD2C FEATURE ENGINEERING COMPLETED:\n• Silver Tables: GDACS alerts & supply chain news\n• Risk Scores: Calculated for all ports\n• Geospatial Analysis: Distance-based risk calculations\n• Sentiment Analysis: Enhanced news impact scoring\n\n\uD83D\uDCC8 RISK ANALYSIS RESULTS:\n• Average Port Risk: 13.9%\n• High Risk Ports: 0 (0.0%)\n• Medium Risk Ports: 0 (0.0%) \n• Low Risk Ports: 19 (100.0%)\n\n\uD83D\uDD0D KEY INSIGHTS:\n• Disaster Correlation: 0.691 (strongest factor)\n• News Impact: 0.951 \n• Regional Variations: 4 regions analyzed\n\n\uD83D\uDE80 READY FOR SUNDAY:\n• MLflow Experiments: ✅ TRACKED\n• Data Pipeline: ✅ OPERATIONAL\n• Risk Models: ✅ CALIBRATED\n• AI Agents: ✅ READY FOR INTEGRATION\n\n➡️ Next: Notebook 4 - LangChain AI Agents & Real-time Monitoring\n\n\n\uD83D\uDD0D FINAL RISK OVERVIEW:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>port_name</th><th>country</th><th>region</th><th>risk_level</th><th>overall_risk</th><th>nearby_disasters_count</th><th>news_mentions</th></tr></thead><tbody><tr><td>Shenzhen</td><td>China</td><td>Asia</td><td>LOW</td><td>0.2901500542711522</td><td>1</td><td>1</td></tr><tr><td>Hong Kong</td><td>China</td><td>Asia</td><td>LOW</td><td>0.2768282066509887</td><td>1</td><td>1</td></tr><tr><td>Long Beach</td><td>USA</td><td>North America</td><td>LOW</td><td>0.26625</td><td>0</td><td>1</td></tr><tr><td>Shanghai</td><td>China</td><td>Asia</td><td>LOW</td><td>0.24</td><td>0</td><td>1</td></tr><tr><td>Salalah</td><td>Oman</td><td>Middle East</td><td>LOW</td><td>0.15000000000000002</td><td>0</td><td>0</td></tr><tr><td>Qingdao</td><td>China</td><td>Asia</td><td>LOW</td><td>0.135</td><td>0</td><td>0</td></tr><tr><td>Savannah</td><td>USA</td><td>North America</td><td>LOW</td><td>0.12750000000000003</td><td>0</td><td>0</td></tr><tr><td>Vancouver</td><td>Canada</td><td>North America</td><td>LOW</td><td>0.12750000000000003</td><td>0</td><td>0</td></tr><tr><td>Felixstowe</td><td>UK</td><td>Europe</td><td>LOW</td><td>0.12000000000000002</td><td>0</td><td>0</td></tr><tr><td>Valencia</td><td>Spain</td><td>Europe</td><td>LOW</td><td>0.12000000000000002</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Shenzhen",
         "China",
         "Asia",
         "LOW",
         0.2901500542711522,
         1,
         1
        ],
        [
         "Hong Kong",
         "China",
         "Asia",
         "LOW",
         0.2768282066509887,
         1,
         1
        ],
        [
         "Long Beach",
         "USA",
         "North America",
         "LOW",
         0.26625,
         0,
         1
        ],
        [
         "Shanghai",
         "China",
         "Asia",
         "LOW",
         0.24,
         0,
         1
        ],
        [
         "Salalah",
         "Oman",
         "Middle East",
         "LOW",
         0.15000000000000002,
         0,
         0
        ],
        [
         "Qingdao",
         "China",
         "Asia",
         "LOW",
         0.135,
         0,
         0
        ],
        [
         "Savannah",
         "USA",
         "North America",
         "LOW",
         0.12750000000000003,
         0,
         0
        ],
        [
         "Vancouver",
         "Canada",
         "North America",
         "LOW",
         0.12750000000000003,
         0,
         0
        ],
        [
         "Felixstowe",
         "UK",
         "Europe",
         "LOW",
         0.12000000000000002,
         0,
         0
        ],
        [
         "Valencia",
         "Spain",
         "Europe",
         "LOW",
         0.12000000000000002,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "port_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "risk_level",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "overall_risk",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "nearby_disasters_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "news_mentions",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "\uD83C\uDF89 SATURDAY WORK COMPLETED SUCCESSFULLY!\n",
    "\n",
    "\uD83D\uDCCA REAL DATA PROCESSING SUMMARY:\n",
    "• Disaster Events: {} events ({} types)\n",
    "• News Articles: {} articles ({} sources)  \n",
    "• Ports Analyzed: {} major global ports\n",
    "• Data Sources: ✅ REAL APIs ONLY\n",
    "\n",
    "\uD83D\uDD2C FEATURE ENGINEERING COMPLETED:\n",
    "• Silver Tables: GDACS alerts & supply chain news\n",
    "• Risk Scores: Calculated for all ports\n",
    "• Geospatial Analysis: Distance-based risk calculations\n",
    "• Sentiment Analysis: Enhanced news impact scoring\n",
    "\n",
    "\uD83D\uDCC8 RISK ANALYSIS RESULTS:\n",
    "• Average Port Risk: {:.1%}\n",
    "• High Risk Ports: {} ({:.1f}%)\n",
    "• Medium Risk Ports: {} ({:.1f}%) \n",
    "• Low Risk Ports: {} ({:.1f}%)\n",
    "\n",
    "\uD83D\uDD0D KEY INSIGHTS:\n",
    "• Disaster Correlation: {:.3f} (strongest factor)\n",
    "• News Impact: {:.3f} \n",
    "• Regional Variations: {} regions analyzed\n",
    "\n",
    "\uD83D\uDE80 READY FOR SUNDAY:\n",
    "• MLflow Experiments: ✅ TRACKED\n",
    "• Data Pipeline: ✅ OPERATIONAL\n",
    "• Risk Models: ✅ CALIBRATED\n",
    "• AI Agents: ✅ READY FOR INTEGRATION\n",
    "\n",
    "➡️ Next: Notebook 4 - LangChain AI Agents & Real-time Monitoring\n",
    "\"\"\".format(\n",
    "    gdacs_stats['total_events'], len(gdacs_stats['event_types']),\n",
    "    news_stats['total_articles'], len(news_stats['sources']),\n",
    "    port_risks_df.count(),\n",
    "    risk_stats.avg_risk or 0.0,\n",
    "    high_risk_ports, (high_risk_ports / port_risks_df.count() * 100) if port_risks_df.count() > 0 else 0,\n",
    "    medium_risk_ports, (medium_risk_ports / port_risks_df.count() * 100) if port_risks_df.count() > 0 else 0,\n",
    "    low_risk_ports, (low_risk_ports / port_risks_df.count() * 100) if port_risks_df.count() > 0 else 0,\n",
    "    corr_results.disaster_correlation or 0,\n",
    "    corr_results.news_correlation or 0,\n",
    "    len(regional_risks.collect())\n",
    "))\n",
    "\n",
    "# Final display of risk overview\n",
    "print(\"\\n\uD83D\uDD0D FINAL RISK OVERVIEW:\")\n",
    "display(port_risks_df.select(\n",
    "    \"port_name\", \"country\", \"region\", \"risk_level\", \n",
    "    \"overall_risk\", \"nearby_disasters_count\", \"news_mentions\"\n",
    ").orderBy(\"overall_risk\", ascending=False).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e48d007-c67c-4083-969a-96923933a6e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_FeatureEnginnering_RiskAnalysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}